---
title: (상산고도서관)추천 시스템 개선방안
date: 2025-05-30 22:45:00 +09:00
categories: [상산고도서관, 백엔드, LLM]
tags: 
  [
    상산고도서관,
    백엔드,
    LLM,
  ]
---
## 기존의 추천 시스템의 문제점
- 웹사이트에는 추천 시스템이 있다. `vercel-ai`라는 엄청난 패키지로 만든건데 사실 간단하게 만들었기 때문에 문제점이 많다
- #### 성능의 문제
  일단 GPT-4o-mini 모델을 사용했는데 이게 생각보다 성능이 떨어진다. 또 문제가 vercel-ai에는 내가 원하는 타입의 형식으로 structure-output 기능이 있는데 이걸 쓰니까 성능이 안나온다. 성능이 안나온다는 말은 추천글을 대충 써준다는 말인데 이게 조금 아쉽다. 일반 GPT을 돌리면 이거보단 잘써주는 느낌이 들었기 때문이다. 

- #### 비용의 문제 
  그리고 무엇보다 돈이 나간다. 내 돈이!!!! 나는 졸업하고 이 학교를 떠야하는데 사용자가 많아져서 나한테 비용이 많이 청구된다? 굉장히 곤란한 일이다. 그래서 무료 LLM을 사용해야한다

- #### 유지보수의 문제
  지금 당장 본 웹사이트로 유지보수 문제 때문에 아주 머리가 아프다. 근데 여기다가 LLM까지 유지보수를 시켜야하는 문제가 있다. 

## 해결방안
- 그렇기에 나는 `성능이 떨어지지 않고`, `돈이 안들며`, `유지보수를 잘 안해도 되는` 그런 시스템을 구축해야한다. 다음은 내가 생각한 방법들이다. 
- #### Render Deploy
  [`Render`](https://render.com/)는 내가 써본 배포 방식중에 제일 깔끔하다. 이건 ebs-2026-voca을 만들때도 썼는데 이건 추후 포스트에서 다루기로 하고 암튼 render을 사용하면 파이썬 환경으로 api 백엔드를 만들기 쉽다. 
  하지만 문제점도 있다. 기본적으로 LLM을 무료로 사용하기 위해서는 로컬에 LLM을 다운로드해야한다. 이는 곧 다운로드하는데 많은 컴퓨팅 자원이 필요하다는 의미이며 render의 무료 플랜으로는 택도 없다.(진짜 무료 플랜 20개는 있어야 돌릴까 말까다). 그렇다고 돈을 쓰자니 이게 매달 결제되는거라 돈이 만만치 않다.
- #### Remix SSR로 LLM 호출하기
  이건 서버가 실행될때 ollama.js로 모델을 미리 불러와놓고 사용하겠다는거다. (지금 보면 미친 소리 같네) ollama.js로 모델을 미리 불러와놓을려면 서버가 실행될때 엄청 오래 걸리는데 이게 생각보다 부담이다. 또 다른 문제는 브라우저에서 이걸 돌리려면 WASM, 무슨 web assembly쪽을 건드려야하는데 여기는 아직 좋은 모델이 잘 안나온다고 한다. 즉 첫번째 조건에 안맞는다.

## 그래서 결론은?
- 결론은 다음과 같은 것들을 쓰기로 했다.
- [`Docker`](https://docker.com/) : 개발 바닥을 바꾼 컨테이너 기반으로 패키지를 관리해주는 좋은 도구
- `Huggingface Spaces` 이걸 사용하면 도커 컨테이너를 그냥 베포하게 해준다. 도커로 api을 만들고 그대로 만들면 api대용으로 쓸 수 있을 것 같다. 
- [`Huggingface`](https://huggingface.co/) : 여기에 있는 모델을 활용해 `fine-tuning`해서 내 계정에 업로드해놓으려고 한다. 이렇게 하면 성능 문제도 해결할 수 있다. 
- 일단 Docker은 무료다. 또 Huggingface Spaces는 그래도 많은 컴퓨팅 자원을 제공해준다. 또 두 패키지 모두 무료이다. 어느정도 쓰기에는 나쁘지 않을거 같다. 
- 유지보수, huggingface에 모델을 업로드만 하면 지 혼자 알아서 다 하기 때문에 유지보수할 일이 없을것이다. 
- 이 내용들을 참고한게 있는데 바로 토스의 기술 블로그이다. 
- [`원문`](https://toss.tech/article/llm-serving) 여기에 보면 LLM을 서빙하는 토스 얘기가 있다. 여기에서 docker에 관련된 내용들을 찾을 수 있었다. 

## 단점
- 물론 단점도 있다
- 일단 ColdStart라고 해서 초기 실행시 오래 걸린다. 이는 당연하게도 huggingface 모델을 불러와야하니까 그렇다. 근데 어차피 내가 한번 실행하느라 무조건 한번쯤은 다운로드하게 되어있다. 
- 다른 문제는 `내가 도커를 모른다!!`

## 소감
- 사실 비밀인데 이거 구상하기까지 2주나 걸렸다. 사실 마음만 먹으면 어? AWS도 쓰고 어? openai도 쓰고 하고 싶은데...비용 청구를 막으려고 하니 문제가 생긴다. 
- 사실 나도 알고 있다. 웹사이트는 항상 유지보수에 시간이 많이 쓰인다...졸업하고 학교 올 일이 많이 생기겠다...
- 이제 도커를 배워야겠다...사실 추천 시스템은 받았던 피드백들 중 극히 일부인데 이게 맞나...
