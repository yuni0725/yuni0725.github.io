---
title: Fine-tuning과 RoLA
date: 2025-06-05 22:20:01 +09:00
categories: [LLM, 논문리뷰]
tags: 
  [
    LLM, 논문리뷰
  ]
---
## `사전학습(pre-trained)`과 `미세조정(fine-tuning)`
- 사전학습과 미세조정은 연애에 비유할 수 있다. 사람이 연애를 하려면 기본적으로 해야 되는것들이 있다. 청결유지, 옷 깔끔하게 입기 뭐 그런것들이 있다. 하지만 이건 말그대로 기본이지 이것만 해서는 성공적인 연애가 될 수 없다. 연애를 시작하게 된다면 그 상대방에게 맞는 사람이 되어야한다. 그 사람에 대해 내가 맞춰지는 것이 중요하다. 
- 웃긴 소리겠지만 이게 사전학습과 미세조정이다. 사전학습은 방대한 텍스트 데이터를 학습한다. 기본적으로 LLM은 텍스트 데이터에서 다음에 올 단어들을 예측한다. 즉, LLM이 우리의 말을 이해하는것이 아닌 단지 다음에 나올 단어들을 예측하면서 단어들을 생성할 수 있게 해준다. 다양한 텍스트 데이터를 참고하므로 우리가 원하는 대답을 원하거나 대답 형식을 기대하기는 어렵다. 그렇기 때문에 우리는 미세조정이 필요하다.
- 미세조정은 사전학습한 데이터보다 작은 지시 데이터셋을 활용해서 모델의 파라미터를 아주 조금씩 바꿀 수 있다. 이는 우리에게 원하는 대답을 하게 하거나 대답 형식을 강제할 수 있다. LLM이 사용자의 요구를 담은 데이터셋을 활용해 사용자에게 특화된 모델이 되는 것이다. 이 과정을 `정렬(alignment)`이라고 한다. 

## 미세조정 해보자!
- 사전학습은 내 컴퓨터로는 어림도 없고 미세조정 정도는 할 수 있다. 그래서 나는 미세조정을 해보려고 했다. 사실 미세조정을 하고 싶은 이유가 학교 도서관 추천 탭을 만들어야하는데 미세조정을 해서 더 나은 추천 이유를 적게 하고 싶었다. 텍스트 생성은 파라미터 개수가 최소 1~2B 모델을 써야한다. 하지만 우리가 쓸 수 있는 서버는 GPU가 없다...
- 그래서 사실 이건 포기했지만 fine-tuning은 해보려고 한다. 
- 내가 fine-tuning할 모델은 카카오에서 한국어 특화 모델로 만든 [`kanana-nano-2.1b-base`](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base) 모델이다.

## 문제는...
- 가장 큰 문제는 데이터셋이다. 데이터셋이 많아야 과적합되지 않는데...내 데이터셋은 1000개밖에 되지 않는다. 이렇게 큰 모델에 지시 데이터셋이 1000개라면 과적합되기 쉽다. 

## 세상에는 똑똑한 사람들이 많다 - LoRA
- 짜잔! 세상에는 나와 비슷한 문제를 고민하는 사람들이 많다. LoRA는 Low Rank Adaptation이라고 한다. 이는 원래 모델의 파라미터를 크게 바꾸지 않으면서 최소한의 것만 바꾼다는 것이다.
- 다시 미세조정으로 돌아가서 미세조정은 데이터셋을 학습해서 모델의 파라미터를 조금씩 바꾼다. 이때 조금씩 바꿀때 전체 파라미터를 바꾸는 것이 아니라 다른 작은 파라미터들을 바꾸면서 가중치를 업데이트하는 것이다. 
- ![이미지](/assets/img/post/BA-matrix.png)
- 이를 식으로 표현하면 $W = W_0 + BA$가 된다. 이는 가중치 행렬에 초기 가중치 행렬에 B,A 매트릭스를 곱한 것을 더해준다. 여기서 B, A는 지도 데이터셋을 학습 시키면서 업데이트되는 가중치 행렬이다. 
- LoRA의 장점은 다음과 같다.
  - 본래 가중치 행렬을 보존하고 BA을 저장하므로써 용도에 따라 BA을 바꿔 끼울 수 있다. (여기서 BA 행렬을 adapter이라고 한다)
  - B, A 행렬은 차원이 원래 행렬보다 굉장히 작다. 파라미터의 개수가 적으니 학습도 빠르다. 
- LoRA을 알아보려고 논문 리뷰도 해봤다. [`LoRA: Low-Rank Adaptation of Large Language Models`](https://arxiv.org/abs/2106.09685)

## 결과
- 아무튼 RoLA을 활용해서 `사서추천도서` 데이터셋을 잘 학습했다. huggingface에 fine-tuning한 모델도 올려봤다. 
- 다음에는 조금 더 데이터셋을 많이 준비하고 GPU도 있으면 더 큰 모델도 학습시켜보고 싶다. 
- ![이미지](/assets/img/post/fine-tuning.png)
- [`모델`](https://huggingface.co/yuni0725/kanana-nano-2.1b-lora-bookrecommendation)
- [`코랩코드`](https://colab.research.google.com/drive/1CBaK2ZcHUpDN2U3DzgSlbq9FSikZQwSW#scrollTo=jlBn-5QJH5IS)

## 소감
- 사실 몇개월전까지만해도 few-shot-prompting과 미세조정을 구분하지 못했다. 내가 미쳤지 진짜
- 근데 확실히 구현해보니 확실히 few-shot-prompting과 다른 것을 알 수 있다. 개인적으로는 미세조정을 할 수 있으면 미세조정을 하는게 훨씬 나은거 같다. 대답 형식을 강제할 수 있기 때문이다. 